Not using distributed mode
[23:23:04.331514] job dir: /home/rb/AtlasGaussians
[23:23:04.331545] Namespace(batch_size=27,
epochs=1000,
replica=8,
accum_iter=1,
model='kl_d512_m512_l16_d24_edm',
config_ae='config/shapenet/train_car_full.yaml',
ae_pth='output/vae/shapenet/vae_car_full/ckpt/checkpoint-999.pth',
clip_grad=None,
weight_decay=0.05,
lr=0.0001,
layer_decay=0.75,
min_lr=1e-06,
warmup_epochs=50,
log_dir='output/ldm/shapenet/car',
latent_dir='output/vae/shapenet/vae_car_full/inference/latents/epoch_1000',
device='cuda',
seed=0,
resume='',
start_epoch=0,
eval=False,
dist_eval=False,
num_workers=10,
pin_mem=True,
world_size=1,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
output_dir='output/ldm/shapenet/car/ckpt',
distributed=False)
[23:23:04.348269] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f940fa9be90>
[23:23:04.380824] Copied datasets/splits/shapenet/02691156_test.txt to output/ldm/shapenet/car/code/datasets/splits/shapenet/02691156_test.txt
[23:23:04.380924] Copied datasets/splits/shapenet/02691156_train.txt to output/ldm/shapenet/car/code/datasets/splits/shapenet/02691156_train.txt
[23:23:04.381136] Copied models_class_cond.py to output/ldm/shapenet/car/code/models_class_cond.py
[23:23:04.381304] Copied profiler/profile_nvtx_infer_log.txt to output/ldm/shapenet/car/code/profiler/profile_nvtx_infer_log.txt
[23:23:04.381349] Copied profiler/profile_nvtx_ldm_log.txt to output/ldm/shapenet/car/code/profiler/profile_nvtx_ldm_log.txt
[23:23:04.381421] Copied profiler/profile_nvtx_vae_log.txt to output/ldm/shapenet/car/code/profiler/profile_nvtx_vae_log.txt
[23:23:04.381568] Copied scripts/train_shape_car.sh to output/ldm/shapenet/car/code/scripts/train_shape_car.sh
[23:23:04.381624] Copied scripts/train_shape_plane.sh to output/ldm/shapenet/car/code/scripts/train_shape_plane.sh
[23:23:04.381688] Copied util/emd/emd_cuda.cu to output/ldm/shapenet/car/code/util/emd/emd_cuda.cu
[23:23:06.041364] Loading autoencoder output/vae/shapenet/vae_car_full/ckpt/checkpoint-999.pth
[23:23:08.076501] Model = EDMPrecond(
  (model): LatentArrayTransformer(
    (proj_in): Linear(in_features=16, out_features=512, bias=False)
    (transformer_blocks): ModuleList(
      (0-23): 24 x BasicTransformerBlock(
        (attn1): CrossAttention(
          (to_q): Linear(in_features=512, out_features=512, bias=False)
          (to_k): Linear(in_features=512, out_features=512, bias=False)
          (to_v): Linear(in_features=512, out_features=512, bias=False)
          (to_out): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Dropout(p=0.0, inplace=False)
          )
        )
        (ff): FeedForward(
          (net): Sequential(
            (0): GEGLU(
              (proj): Linear(in_features=512, out_features=4096, bias=True)
            )
            (1): Dropout(p=0.0, inplace=False)
            (2): Linear(in_features=2048, out_features=512, bias=True)
          )
        )
        (attn2): CrossAttention(
          (to_q): Linear(in_features=512, out_features=512, bias=False)
          (to_k): Linear(in_features=512, out_features=512, bias=False)
          (to_v): Linear(in_features=512, out_features=512, bias=False)
          (to_out): Sequential(
            (0): Linear(in_features=512, out_features=512, bias=True)
            (1): Dropout(p=0.0, inplace=False)
          )
        )
        (norm1): AdaLayerNorm(
          (silu): SiLU()
          (linear): Linear(in_features=512, out_features=1024, bias=True)
          (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
        )
        (norm2): AdaLayerNorm(
          (silu): SiLU()
          (linear): Linear(in_features=512, out_features=1024, bias=True)
          (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
        )
        (norm3): AdaLayerNorm(
          (silu): SiLU()
          (linear): Linear(in_features=512, out_features=1024, bias=True)
          (layernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (ls2): Identity()
        (drop_path2): Identity()
        (ls3): Identity()
        (drop_path3): Identity()
      )
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
    (proj_out): Linear(in_features=512, out_features=16, bias=False)
    (map_noise): PositionalEmbedding()
    (map_layer0): Linear(in_features=256, out_features=512, bias=True)
    (map_layer1): Linear(in_features=512, out_features=512, bias=True)
  )
)
[23:23:08.076516] number of params (M): 164.20
[23:23:08.076521] actual lr: 1.00e-04
[23:23:08.076523] accumulate grad iterations: 1
[23:23:08.076524] effective batch size: 27
[23:23:08.077173] criterion = <models_class_cond_profile_nvtx.EDMLoss object at 0x7f940c2e97c0>
[23:23:08.077179] Start training for 1000 epochs
[23:23:08.078415] log_dir: output/ldm/shapenet/car
[23:23:08.964084] Epoch: [0]  [0/2]  eta: 0:00:01  lr: 0.000000  loss: 0.9755 (0.9755)  time: 0.8092  data: 0.1911  max mem: 27316
[23:23:09.388895] Epoch: [0]  [1/2]  eta: 0:00:00  lr: 0.000001  loss: 0.9755 (0.9774)  time: 0.6169  data: 0.0956  max mem: 28539
[23:23:09.423238] Epoch: [0] Total time: 0:00:01 (0.6344 s / it)
[23:23:09.423268] Averaged stats: lr: 0.000001  loss: 0.9755 (0.9774)
[23:23:10.737780] Test:  [0/2]  eta: 0:00:00  loss: 1.0002 (1.0002)  time: 0.1697  data: 0.1511  max mem: 28539
[23:23:10.748970] Test:  [1/2]  eta: 0:00:00  loss: 1.0002 (1.0008)  time: 0.0904  data: 0.0756  max mem: 28539
[23:23:10.779574] Test: Total time: 0:00:00 (0.1059 s / it)
[23:23:10.779607] * loss 1.001
[23:23:10.779671] loss of the network on the 2 test images: 1.001
[23:23:10.781785] log_dir: output/ldm/shapenet/car
[23:23:11.395985] Epoch: [1]  [0/2]  eta: 0:00:01  lr: 0.000002  loss: 0.9772 (0.9772)  time: 0.6104  data: 0.1524  max mem: 28540
[23:23:11.873366] Epoch: [1]  [1/2]  eta: 0:00:00  lr: 0.000003  loss: 0.9772 (0.9837)  time: 0.5438  data: 0.0762  max mem: 28540
[23:23:11.904382] Epoch: [1] Total time: 0:00:01 (0.5596 s / it)
[23:23:11.904410] Averaged stats: lr: 0.000003  loss: 0.9772 (0.9837)
[23:23:11.907600] log_dir: output/ldm/shapenet/car
[23:23:12.511641] Epoch: [2]  [0/2]  eta: 0:00:01  lr: 0.000004  loss: 0.9762 (0.9762)  time: 0.6002  data: 0.1409  max mem: 28540
[23:23:12.990288] Epoch: [2]  [1/2]  eta: 0:00:00  lr: 0.000005  loss: 0.9762 (0.9784)  time: 0.5393  data: 0.0705  max mem: 28540
[23:23:13.022612] Epoch: [2] Total time: 0:00:01 (0.5558 s / it)
[23:23:13.022639] Averaged stats: lr: 0.000005  loss: 0.9762 (0.9784)
[23:23:13.024204] Training time 0:00:04
Collecting data...
Generating '/tmp/nsys-report-5d2f.qdstrm'
[1/1] [0%                          ] ldm.nsys-rep[1/1] [0%                          ] ldm.nsys-rep[1/1] [=16%                        ] ldm.nsys-rep[1/1] [=====29%                    ] ldm.nsys-rep[1/1] [========42%                 ] ldm.nsys-rep[1/1] [============54%             ] ldm.nsys-rep[1/1] [===============67%          ] ldm.nsys-rep[1/1] [==================75%       ] ldm.nsys-rep[1/1] [========================100%] ldm.nsys-rep[1/1] [========================100%] ldm.nsys-rep
Generated:
	/home/rb/AtlasGaussians/profiler/ldm.nsys-rep
